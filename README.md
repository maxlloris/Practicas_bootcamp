# Advanced SQL, ETL, and DataWarehouse Module

For the Spanish version, click [here](#Módulo-de-SQL-Avanzado-ETL-y-DataWarehouse)

### **Repository Content**

This repository contains my solution for the practical exercise of this module, which focuses on advanced SQL concepts, ETL processes, and DataWarehouse implementation. It follows a methodology based on best practices applied to realistic scenarios involving large datasets and transformation processes.

In this module, I worked with the following tools:
- **PostgreSQL (TablePlus)**: For designing and managing relational databases locally.
- **BigQuery**: For analyzing and processing large datasets in the cloud, using SQL standard and BigQuery-specific extensions.

Both tools have been key to implementing robust and optimized solutions in different environments.<br><br>

---

## **Module Content**

### **Database Design**
Database design includes creating Entity-Relationship (ER) diagrams and implementing them in SQL. This process ensures data is logically and efficiently organized.

- Entity-Relationship diagram for the Keepcoding database.
- SQL script with table creation commands based on the ER diagram.

### **ETL (Extract, Transform, Load)**
ETL focuses on extracting, transforming, and loading data into a structured and clean format for analysis.

- SQL script to create the `ivr_detail` table, designed to capture detailed IVR (Interactive Voice Response) information.
- SQL script to create the `ivr_summary` table, aimed at storing aggregated information from `ivr_detail`.
- Scripts for cleaning `NULL` values in integer columns to improve data quality.

### **DataWarehouse**
A DataWarehouse provides an optimized architecture for data analysis. This module covers:

- Creating tables optimized for analytical queries.
- Implementing cleaning and normalization processes for consistent and efficient data.

---

## **Tools Used**

- **PostgreSQL (TablePlus)**: Used for designing and executing queries on local relational databases.
- **BigQuery**: Used for analyzing large datasets in a cloud environment with SQL standard.

---

This module provides a comprehensive approach to solving complex problems related to databases, ETL processes, and DataWarehouses.
<br><br>




# Módulo de SQL Avanzado, ETL y DataWarehouse

Para versión en inglés haz clic [aquí](#Advanced-SQL-ETL-and-DataWarehouse-Module)

### **Contenido del repositorio**

Este repositorio contiene mi solución para la práctica de este módulo, donde abordamos conceptos avanzados de SQL, diseño de ETL y la implementación de un DataWarehouse. Se sigue una metodología basada en buenas prácticas, aplicada a escenarios realistas que involucran grandes volúmenes de datos y procesos de transformación.

En este módulo he trabajado con las siguientes herramientas:
- **PostgreSQL (TablePlus)**: Para el diseño y gestión de bases de datos relacionales locales.
- **BigQuery**: Para el análisis y procesamiento de grandes volúmenes de datos en la nube, utilizando SQL estándar y extensiones propias de BigQuery.

Ambas herramientas han sido clave para implementar soluciones robustas y optimizadas en diferentes entornos.<br><br>

---

## **Contenido del módulo**

### **Diseño de Bases de Datos**
El diseño de bases de datos incluye la creación de diagramas entidad-relación (ER) y su implementación en SQL. Este proceso garantiza que los datos estén organizados de manera lógica y eficiente.

- Diagrama entidad-relación para la base de datos de Keepcoding.
- Archivo SQL con scripts para la creación de las tablas basadas en el diagrama ER.

### **ETL (Extract, Transform, Load)**
El proceso de ETL se centra en la extracción, transformación y carga de datos en un formato estructurado y limpio para su uso en análisis.

- Archivo SQL para la creación de la tabla `ivr_detail`, diseñada para capturar información detallada de IVR (Interactive Voice Response).
- Archivo SQL para la creación de la tabla `ivr_summary`, destinada a almacenar información agregada a partir de `ivr_detail`.
- Scripts para la limpieza de valores `NULL` en columnas de tipo entero, mejorando la calidad de los datos.

### **DataWarehouse**
Un DataWarehouse proporciona una arquitectura optimizada para análisis de datos. Este módulo abarca:

- Creación de tablas optimizadas para consultas analíticas.
- Implementación de procesos de limpieza y normalización para datos consistentes y eficientes.

---

## **Herramientas utilizadas**

- **PostgreSQL (TablePlus)**: Herramienta utilizada para el diseño y la ejecución de consultas en bases de datos relacionales locales.
- **BigQuery**: Herramienta utilizada para analizar grandes volúmenes de datos en un entorno de nube con SQL estándar.

---

Este módulo proporciona un enfoque integral para resolver problemas complejos relacionados con bases de datos, ETL y DataWarehouses.

